{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87139bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Blacklight data for http://tapresearch.com...\n",
      "Saved data for tapresearch.com to ./blacklight_json/tapresearch.com.json\n",
      "Fetching Blacklight data for http://theatlantic.com...\n",
      "Logged error for theatlantic.com\n",
      "Fetching Blacklight data for http://theoremreach.com...\n",
      "Saved data for theoremreach.com to ./blacklight_json/theoremreach.com.json\n",
      "Fetching Blacklight data for http://travelquiz.com...\n",
      "Saved data for travelquiz.com to ./blacklight_json/travelquiz.com.json\n",
      "Fetching Blacklight data for http://traveltrivia.com...\n",
      "Saved data for traveltrivia.com to ./blacklight_json/traveltrivia.com.json\n",
      "Fetching Blacklight data for http://trekbaron.com...\n",
      "Saved data for trekbaron.com to ./blacklight_json/trekbaron.com.json\n",
      "Fetching Blacklight data for http://triptrivia.com...\n",
      "Saved data for triptrivia.com to ./blacklight_json/triptrivia.com.json\n",
      "Fetching Blacklight data for http://triviaclue.com...\n",
      "Saved data for triviaclue.com to ./blacklight_json/triviaclue.com.json\n",
      "Processed 2560 websites. Pausing for 20 seconds...\n",
      "Fetching Blacklight data for http://triviadaily.com...\n",
      "Logged error for triviadaily.com\n",
      "Fetching Blacklight data for http://triviagenius.com...\n",
      "Saved data for triviagenius.com to ./blacklight_json/triviagenius.com.json\n",
      "Fetching Blacklight data for http://triviapop.com...\n",
      "Saved data for triviapop.com to ./blacklight_json/triviapop.com.json\n",
      "Fetching Blacklight data for http://untappedcities.com...\n",
      "Logged error for untappedcities.com\n",
      "Processed 2565 websites. Pausing for 20 seconds...\n",
      "Fetching Blacklight data for http://upside.com...\n",
      "Saved data for upside.com to ./blacklight_json/upside.com.json\n",
      "Fetching Blacklight data for http://viralbezz.com...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Blacklight API endpoint\n",
    "BLACKLIGHT_ENDPOINT = 'https://blacklight-us-ca.api.themarkup.org'\n",
    "\n",
    "# Setup logging\n",
    "LOG_FILE = \"error_log.json\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE,\n",
    "    level=logging.ERROR,\n",
    "    format='{\"timestamp\": \"%(asctime)s\", \"level\": \"%(levelname)s\", \"domain_name\": \"%(domain_name)s\", \"url\": \"%(url)s\", \"error_message\": \"%(error_message)s\"}',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# Function to get privacy data from Blacklight\n",
    "def get_blacklight_privacy_data(url):\n",
    "    try:\n",
    "        data = {\"inUrl\": url}\n",
    "        r = requests.post(url=BLACKLIGHT_ENDPOINT, json=data)\n",
    "        r.raise_for_status()  # Raise HTTPError for bad responses (4xx and 5xx)\n",
    "        return r.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"Error fetching data for {url}: {e}\")\n",
    "\n",
    "# Function to save JSON data to a file\n",
    "def write_json_to_file(json_data, file_path):\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(json_data, json_file, indent=2)\n",
    "\n",
    "# Load and deduplicate websites\n",
    "websites = pd.read_csv(\"../data/yg_ind_domain.csv\")[[\"private_domain\"]].drop_duplicates()[2000:]\n",
    "\n",
    "# Define the output folder\n",
    "output_folder = \"./blacklight_json\"\n",
    "os.makedirs(output_folder, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "\n",
    "for idx, row in websites.iterrows():\n",
    "    domain_name = row[\"private_domain\"]\n",
    "    url = f\"http://{domain_name}\"  # Ensure proper URL format\n",
    "\n",
    "    # Define the output file path\n",
    "    output_file = os.path.join(output_folder, f\"{domain_name}.json\")\n",
    "\n",
    "    # Skip if the file already exists\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Skipping {domain_name}... (File already exists)\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Fetching Blacklight data for {url}...\")\n",
    "\n",
    "    try:\n",
    "        # Fetch the data\n",
    "        blacklight_data = get_blacklight_privacy_data(url)\n",
    "\n",
    "        # Add the domain name to the data for reference\n",
    "        blacklight_data[\"domain_name\"] = domain_name\n",
    "\n",
    "        # Write to the JSON file\n",
    "        write_json_to_file(blacklight_data, output_file)\n",
    "        print(f\"Saved data for {domain_name} to {output_file}\")\n",
    "    except Exception as e:\n",
    "        # Log the error using logging\n",
    "        logging.error(\n",
    "            \"An error occurred while fetching Blacklight data.\",\n",
    "            extra={\n",
    "                \"domain_name\": domain_name,\n",
    "                \"url\": url,\n",
    "                \"error_message\": str(e)\n",
    "            }\n",
    "        )\n",
    "        print(f\"Logged error for {domain_name}\")\n",
    "\n",
    "    # Pause for 10 seconds after every 5 websites\n",
    "    if (idx + 1) % 5 == 0:\n",
    "        print(f\"Processed {idx + 1} websites. Pausing for 20 seconds...\")\n",
    "        time.sleep(20)\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a301f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
