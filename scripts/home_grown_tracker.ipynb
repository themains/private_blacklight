{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b7eaca4-ba1d-4f5d-9931-26f30532533e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-15 18:55:49,103 - INFO - Loaded 30 default trackers\n"
     ]
    }
   ],
   "source": [
    "# Web Tracker Analysis using Firefox\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import csv\n",
    "import urllib.parse\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Set, Any, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "# You'll need to install these packages if you don't have them:\n",
    "# !pip install selenium webdriver-manager pandas tldextract\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "import pandas as pd\n",
    "import tldextract\n",
    "\n",
    "# Configure logging to display in the notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Tracker categories\n",
    "TRACKER_CATEGORIES = {\n",
    "    'advertising': 'Advertising',\n",
    "    'audio_video': 'Audio/Video Player',\n",
    "    'customer_interaction': 'Customer Interaction',\n",
    "    'hosting': 'Hosting Services',\n",
    "    'consent': 'Consent Management',\n",
    "    'analytics': 'Site Analytics',\n",
    "    'misc': 'Miscellaneous',\n",
    "    'utility': 'Utilities',\n",
    "    'social': 'Social Media',\n",
    "    'adult_advertising': 'Adult Advertising'\n",
    "}\n",
    "\n",
    "class Request:\n",
    "    \"\"\"Class to represent a network request.\"\"\"\n",
    "    def __init__(self, url: str, resource_type: str, size: int):\n",
    "        self.url = url\n",
    "        self.resource_type = resource_type\n",
    "        self.size = size  # Size in bytes\n",
    "        self.domain = self.extract_domain(url)\n",
    "        self.timestamp = time.time()\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_domain(url: str) -> str:\n",
    "        \"\"\"Extract root domain from URL.\"\"\"\n",
    "        try:\n",
    "            ext = tldextract.extract(url)\n",
    "            return f\"{ext.domain}.{ext.suffix}\"\n",
    "        except:\n",
    "            return urllib.parse.urlparse(url).netloc\n",
    "\n",
    "class TrackerDatabase:\n",
    "    \"\"\"Database of known trackers and their categories.\"\"\"\n",
    "    def __init__(self, database_file: Optional[str] = None):\n",
    "        self.trackers = {}\n",
    "        self.categories = defaultdict(list)\n",
    "        \n",
    "        # Load from file if provided\n",
    "        if database_file and os.path.exists(database_file):\n",
    "            self.load_database(database_file)\n",
    "        else:\n",
    "            self.load_default_database()\n",
    "    \n",
    "    def load_database(self, database_file: str) -> None:\n",
    "        \"\"\"Load tracker database from JSON file.\"\"\"\n",
    "        try:\n",
    "            with open(database_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                self.trackers = data.get('trackers', {})\n",
    "                \n",
    "                # Build category index\n",
    "                for domain, info in self.trackers.items():\n",
    "                    if 'category' in info:\n",
    "                        self.categories[info['category']].append(domain)\n",
    "                \n",
    "            logging.info(f\"Loaded {len(self.trackers)} trackers from {database_file}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading tracker database: {e}\")\n",
    "            self.load_default_database()\n",
    "    \n",
    "    def load_default_database(self) -> None:\n",
    "        \"\"\"Load a default set of common trackers.\"\"\"\n",
    "        # This is a minimal set - in practice you would want a comprehensive database\n",
    "        default_trackers = {\n",
    "            \"google-analytics.com\": {\"name\": \"Google Analytics\", \"category\": \"analytics\"},\n",
    "            \"doubleclick.net\": {\"name\": \"DoubleClick\", \"category\": \"advertising\"},\n",
    "            \"facebook.net\": {\"name\": \"Facebook\", \"category\": \"social\"},\n",
    "            \"fonts.googleapis.com\": {\"name\": \"Google Fonts\", \"category\": \"utility\"},\n",
    "            \"hotjar.com\": {\"name\": \"Hotjar\", \"category\": \"analytics\"},\n",
    "            \"youtube.com\": {\"name\": \"YouTube\", \"category\": \"audio_video\"},\n",
    "            \"criteo.com\": {\"name\": \"Criteo\", \"category\": \"advertising\"},\n",
    "            \"taboola.com\": {\"name\": \"Taboola\", \"category\": \"advertising\"},\n",
    "            \"outbrain.com\": {\"name\": \"Outbrain\", \"category\": \"advertising\"},\n",
    "            \"cloudflare.com\": {\"name\": \"Cloudflare\", \"category\": \"hosting\"},\n",
    "            \"cdn.cookielaw.org\": {\"name\": \"OneTrust\", \"category\": \"consent\"},\n",
    "            \"intercom.io\": {\"name\": \"Intercom\", \"category\": \"customer_interaction\"},\n",
    "            \"stripe.com\": {\"name\": \"Stripe\", \"category\": \"utility\"},\n",
    "            \"twitter.com\": {\"name\": \"Twitter\", \"category\": \"social\"},\n",
    "            \"googleapis.com\": {\"name\": \"Google APIs\", \"category\": \"utility\"},\n",
    "            \"gstatic.com\": {\"name\": \"Google Static\", \"category\": \"utility\"},\n",
    "            \"amazon-adsystem.com\": {\"name\": \"Amazon Ads\", \"category\": \"advertising\"},\n",
    "            \"googletagmanager.com\": {\"name\": \"Google Tag Manager\", \"category\": \"utility\"},\n",
    "            \"adnxs.com\": {\"name\": \"AppNexus\", \"category\": \"advertising\"},\n",
    "            \"cookiebot.com\": {\"name\": \"Cookiebot\", \"category\": \"consent\"},\n",
    "            \"fastly.net\": {\"name\": \"Fastly\", \"category\": \"hosting\"},\n",
    "            \"akamaihd.net\": {\"name\": \"Akamai\", \"category\": \"hosting\"},\n",
    "            \"optimizely.com\": {\"name\": \"Optimizely\", \"category\": \"analytics\"},\n",
    "            \"segment.io\": {\"name\": \"Segment\", \"category\": \"analytics\"},\n",
    "            \"fontawesome.com\": {\"name\": \"Font Awesome\", \"category\": \"utility\"},\n",
    "            \"piwik.pro\": {\"name\": \"Piwik\", \"category\": \"analytics\"},\n",
    "            \"tiqcdn.com\": {\"name\": \"Tealium\", \"category\": \"analytics\"},\n",
    "            \"mixpanel.com\": {\"name\": \"Mixpanel\", \"category\": \"analytics\"},\n",
    "            \"jsdelivr.net\": {\"name\": \"jsDelivr\", \"category\": \"hosting\"},\n",
    "            \"unpkg.com\": {\"name\": \"Unpkg\", \"category\": \"hosting\"}\n",
    "        }\n",
    "        \n",
    "        self.trackers = default_trackers\n",
    "        \n",
    "        # Build category index\n",
    "        for domain, info in self.trackers.items():\n",
    "            if 'category' in info:\n",
    "                self.categories[info['category']].append(domain)\n",
    "        \n",
    "        logging.info(f\"Loaded {len(self.trackers)} default trackers\")\n",
    "    \n",
    "    def is_tracker(self, domain: str) -> bool:\n",
    "        \"\"\"Check if a domain is a known tracker.\"\"\"\n",
    "        # Direct match\n",
    "        if domain in self.trackers:\n",
    "            return True\n",
    "        \n",
    "        # Subdomain match\n",
    "        for tracker_domain in self.trackers:\n",
    "            if domain.endswith(f\".{tracker_domain}\"):\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def get_tracker_info(self, domain: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Get information about a tracker.\"\"\"\n",
    "        # Direct match\n",
    "        if domain in self.trackers:\n",
    "            return self.trackers[domain]\n",
    "        \n",
    "        # Subdomain match\n",
    "        for tracker_domain in self.trackers:\n",
    "            if domain.endswith(f\".{tracker_domain}\"):\n",
    "                return self.trackers[tracker_domain]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def get_category(self, domain: str) -> str:\n",
    "        \"\"\"Get category of a tracker.\"\"\"\n",
    "        info = self.get_tracker_info(domain)\n",
    "        if info and 'category' in info:\n",
    "            return info['category']\n",
    "        return 'misc'  # Default category for unknown trackers\n",
    "\n",
    "class WebsiteAnalyzer:\n",
    "    \"\"\"Analyzes a website for trackers using Firefox.\"\"\"\n",
    "    def __init__(self, tracker_db: TrackerDatabase, headless: bool = True):\n",
    "        self.tracker_db = tracker_db\n",
    "        self.headless = headless\n",
    "        self.driver = None\n",
    "        self.requests = []\n",
    "        self.setup_driver()\n",
    "    \n",
    "    def setup_driver(self) -> None:\n",
    "        \"\"\"Set up the Selenium WebDriver.\"\"\"\n",
    "        options = Options()\n",
    "        if self.headless:\n",
    "            options.add_argument(\"--headless\")\n",
    "        \n",
    "        options.add_argument(\"--width=1920\")\n",
    "        options.add_argument(\"--height=1080\")\n",
    "        \n",
    "        # Enable network request interception via DevTools\n",
    "        options.set_preference(\"devtools.netmonitor.enabled\", True)\n",
    "        options.set_preference(\"devtools.netmonitor.har.enableAutoExportToFile\", False)\n",
    "        options.set_preference(\"devtools.netmonitor.har.defaultLogDir\", os.getcwd())\n",
    "        options.set_preference(\"devtools.netmonitor.har.defaultFileName\", \"network.har\")\n",
    "        options.log.level = \"trace\"\n",
    "        \n",
    "        try:\n",
    "            self.driver = webdriver.Firefox(\n",
    "                service=Service(GeckoDriverManager().install()),\n",
    "                options=options\n",
    "            )\n",
    "            logging.info(\"Firefox WebDriver initialized\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to initialize Firefox WebDriver: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def analyze_website(self, url: str, timeout: int = 30) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Visit a website and analyze trackers.\n",
    "        \n",
    "        Args:\n",
    "            url: Website URL to analyze\n",
    "            timeout: Page load timeout in seconds\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with tracker analysis results\n",
    "        \"\"\"\n",
    "        logging.info(f\"Analyzing website: {url}\")\n",
    "        \n",
    "        if not self.driver:\n",
    "            self.setup_driver()\n",
    "        \n",
    "        # Reset requests\n",
    "        self.requests = []\n",
    "        \n",
    "        try:\n",
    "            # Navigate to the URL\n",
    "            self.driver.get(url)\n",
    "            \n",
    "            # Wait for page to load\n",
    "            time.sleep(timeout)\n",
    "            \n",
    "            # Get all network requests\n",
    "            # In Firefox, we need to extract this information differently\n",
    "            # We'll use the page source and resource timing API to get a list of loaded resources\n",
    "            resources = self.driver.execute_script(\"\"\"\n",
    "                var resources = [];\n",
    "                var entries = performance.getEntriesByType('resource');\n",
    "                for (var i = 0; i < entries.length; i++) {\n",
    "                    var entry = entries[i];\n",
    "                    resources.push({\n",
    "                        url: entry.name,\n",
    "                        type: entry.initiatorType,\n",
    "                        size: entry.transferSize\n",
    "                    });\n",
    "                }\n",
    "                return resources;\n",
    "            \"\"\")\n",
    "            \n",
    "            # Process resources\n",
    "            for resource in resources:\n",
    "                request = Request(\n",
    "                    url=resource.get('url', ''),\n",
    "                    resource_type=resource.get('type', 'unknown'),\n",
    "                    size=resource.get('size', 0)\n",
    "                )\n",
    "                self.requests.append(request)\n",
    "            \n",
    "            # Analyze requests\n",
    "            return self.analyze_requests(url)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error analyzing {url}: {e}\")\n",
    "            return {\n",
    "                \"url\": url,\n",
    "                \"error\": str(e),\n",
    "                \"trackers\": 0,\n",
    "                \"tracking_requests\": 0,\n",
    "                \"data_transferred\": 0,\n",
    "                \"categories\": {}\n",
    "            }\n",
    "    \n",
    "    def analyze_requests(self, base_url: str) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze collected requests to identify trackers.\"\"\"\n",
    "        base_domain = Request.extract_domain(base_url)\n",
    "        \n",
    "        # Counts\n",
    "        tracker_domains = set()\n",
    "        tracking_requests = []\n",
    "        data_transferred = 0\n",
    "        \n",
    "        # Categorized tracking requests\n",
    "        categories = defaultdict(int)\n",
    "        \n",
    "        # Analyze requests\n",
    "        for request in self.requests:\n",
    "            # Skip requests to the same domain\n",
    "            if request.domain == base_domain:\n",
    "                continue\n",
    "            \n",
    "            # Check if this is a tracker\n",
    "            if self.tracker_db.is_tracker(request.domain):\n",
    "                tracker_domains.add(request.domain)\n",
    "                tracking_requests.append(request)\n",
    "                data_transferred += request.size\n",
    "                \n",
    "                # Categorize the request\n",
    "                category = self.tracker_db.get_category(request.domain)\n",
    "                categories[category] += 1\n",
    "        \n",
    "        # Prepare results\n",
    "        results = {\n",
    "            \"url\": base_url,\n",
    "            \"domain\": base_domain,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"trackers\": len(tracker_domains),\n",
    "            \"tracking_requests\": len(tracking_requests),\n",
    "            \"data_transferred\": data_transferred,\n",
    "            \"categories\": {}\n",
    "        }\n",
    "        \n",
    "        # Format categories for output\n",
    "        for category, count in categories.items():\n",
    "            results[\"categories\"][TRACKER_CATEGORIES.get(category, category)] = count\n",
    "        \n",
    "        # Ensure all categories are represented\n",
    "        for key, label in TRACKER_CATEGORIES.items():\n",
    "            if label not in results[\"categories\"]:\n",
    "                results[\"categories\"][label] = 0\n",
    "        \n",
    "        logging.info(f\"Analysis complete: {results['trackers']} trackers, {results['tracking_requests']} tracking requests\")\n",
    "        return results\n",
    "    \n",
    "    def close(self) -> None:\n",
    "        \"\"\"Close the WebDriver.\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "            self.driver = None\n",
    "            logging.info(\"WebDriver closed\")\n",
    "\n",
    "class AnalysisManager:\n",
    "    \"\"\"Manages the analysis of multiple websites.\"\"\"\n",
    "    def __init__(self, tracker_db_file: Optional[str] = None, output_dir: str = \"results\"):\n",
    "        self.tracker_db = TrackerDatabase(tracker_db_file)\n",
    "        self.output_dir = output_dir\n",
    "        self.analyzer = None\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    def analyze_urls(self, urls: List[str], timeout: int = 30) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Analyze a list of websites.\n",
    "        \n",
    "        Args:\n",
    "            urls: List of URLs to analyze\n",
    "            timeout: Timeout in seconds for each page load\n",
    "            \n",
    "        Returns:\n",
    "            List of analysis results\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        self.analyzer = WebsiteAnalyzer(self.tracker_db)\n",
    "        \n",
    "        for i, url in enumerate(urls):\n",
    "            logging.info(f\"Analyzing ({i+1}/{len(urls)}): {url}\")\n",
    "            try:\n",
    "                result = self.analyzer.analyze_website(url, timeout)\n",
    "                results.append(result)\n",
    "                \n",
    "                # Save interim results after each site\n",
    "                if results:\n",
    "                    interim_filename = os.path.join(self.output_dir, f\"interim_results_{i+1}.json\")\n",
    "                    with open(interim_filename, 'w') as f:\n",
    "                        json.dump(results, f, indent=2)\n",
    "                    logging.info(f\"Saved interim results to {interim_filename}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error analyzing {url}: {e}\")\n",
    "        \n",
    "        # Clean up\n",
    "        if self.analyzer:\n",
    "            self.analyzer.close()\n",
    "        \n",
    "        # Save final results\n",
    "        if results:\n",
    "            self.save_results(results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_results(self, results: List[Dict[str, Any]]) -> None:\n",
    "        \"\"\"Save analysis results to files.\"\"\"\n",
    "        # Create a timestamp for filenames\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        \n",
    "        # Save raw JSON\n",
    "        json_file = os.path.join(self.output_dir, f\"tracker_analysis_{timestamp}.json\")\n",
    "        with open(json_file, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        \n",
    "        # Save summary CSV\n",
    "        csv_file = os.path.join(self.output_dir, f\"tracker_summary_{timestamp}.csv\")\n",
    "        self.save_summary_csv(results, csv_file)\n",
    "        \n",
    "        # Save detailed stats\n",
    "        stats_file = os.path.join(self.output_dir, f\"tracker_stats_{timestamp}.csv\")\n",
    "        self.save_detailed_stats(results, stats_file)\n",
    "        \n",
    "        logging.info(f\"Results saved to {self.output_dir}\")\n",
    "        \n",
    "        # Return the paths to the files\n",
    "        return {\n",
    "            'json': json_file,\n",
    "            'summary': csv_file,\n",
    "            'stats': stats_file\n",
    "        }\n",
    "    \n",
    "    def save_summary_csv(self, results: List[Dict[str, Any]], filename: str) -> None:\n",
    "        \"\"\"Save a summary CSV of the results.\"\"\"\n",
    "        with open(filename, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            \n",
    "            # Write header\n",
    "            writer.writerow([\n",
    "                'URL', 'Domain', 'Timestamp', 'Trackers', \n",
    "                'Tracking Requests', 'Data Transferred (bytes)',\n",
    "                *[label for _, label in sorted(TRACKER_CATEGORIES.items())]\n",
    "            ])\n",
    "            \n",
    "            # Write data\n",
    "            for result in results:\n",
    "                row = [\n",
    "                    result['url'],\n",
    "                    result['domain'],\n",
    "                    result['timestamp'],\n",
    "                    result['trackers'],\n",
    "                    result['tracking_requests'],\n",
    "                    result['data_transferred']\n",
    "                ]\n",
    "                \n",
    "                # Add category counts\n",
    "                for _, label in sorted(TRACKER_CATEGORIES.items()):\n",
    "                    row.append(result['categories'].get(label, 0))\n",
    "                \n",
    "                writer.writerow(row)\n",
    "    \n",
    "    def save_detailed_stats(self, results: List[Dict[str, Any]], filename: str) -> None:\n",
    "        \"\"\"Calculate and save detailed statistics.\"\"\"\n",
    "        if not results:\n",
    "            return\n",
    "        \n",
    "        # Prepare dataframe\n",
    "        df = pd.DataFrame(results)\n",
    "        \n",
    "        # Extract category columns\n",
    "        for category_label in TRACKER_CATEGORIES.values():\n",
    "            df[category_label] = df['categories'].apply(lambda x: x.get(category_label, 0))\n",
    "        \n",
    "        # Drop the categories column\n",
    "        df = df.drop(columns=['categories'])\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats = {}\n",
    "        numeric_columns = [\n",
    "            'trackers', 'tracking_requests', 'data_transferred',\n",
    "            *TRACKER_CATEGORIES.values()\n",
    "        ]\n",
    "        \n",
    "        for col in numeric_columns:\n",
    "            if col in df.columns:\n",
    "                stats[f\"{col}_count\"] = df[col].count()\n",
    "                stats[f\"{col}_mean\"] = df[col].mean()\n",
    "                stats[f\"{col}_std\"] = df[col].std()\n",
    "                stats[f\"{col}_min\"] = df[col].min()\n",
    "                stats[f\"{col}_25%\"] = df[col].quantile(0.25)\n",
    "                stats[f\"{col}_median\"] = df[col].median()\n",
    "                stats[f\"{col}_75%\"] = df[col].quantile(0.75)\n",
    "                stats[f\"{col}_max\"] = df[col].max()\n",
    "        \n",
    "        # Save stats to CSV\n",
    "        with open(filename, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            \n",
    "            # Write header and data\n",
    "            writer.writerow(['Metric', 'Count', 'Mean', 'Std', 'Min', '25%', 'Median', '75%', 'Max'])\n",
    "            \n",
    "            for col in numeric_columns:\n",
    "                if col in df.columns:\n",
    "                    writer.writerow([\n",
    "                        col, \n",
    "                        stats[f\"{col}_count\"],\n",
    "                        round(stats[f\"{col}_mean\"], 2),\n",
    "                        round(stats[f\"{col}_std\"], 2),\n",
    "                        stats[f\"{col}_min\"],\n",
    "                        round(stats[f\"{col}_25%\"], 2),\n",
    "                        round(stats[f\"{col}_median\"], 2),\n",
    "                        round(stats[f\"{col}_75%\"], 2),\n",
    "                        stats[f\"{col}_max\"]\n",
    "                    ])\n",
    "        \n",
    "        # Return the stats dataframe for display\n",
    "        return pd.read_csv(filename)\n",
    "\n",
    "# Example usage in Jupyter notebook\n",
    "# First install the required packages\n",
    "# !pip install selenium webdriver-manager pandas tldextract\n",
    "\n",
    "# Define your list of URLs to analyze\n",
    "urls_to_analyze = [\n",
    "    \"https://example.com\",\n",
    "    \"https://nytimes.com\",\n",
    "    # Add more URLs here\n",
    "]\n",
    "\n",
    "# Create a directory for results\n",
    "output_directory = \"tracker_results\"\n",
    "\n",
    "# Initialize the analysis manager\n",
    "manager = AnalysisManager(output_dir=output_directory)\n",
    "\n",
    "# Run the analysis\n",
    "# results = manager.analyze_urls(urls_to_analyze)\n",
    "\n",
    "# Display the results (if you've run the analysis)\n",
    "# import pandas as pd\n",
    "# stats_files = [f for f in os.listdir(output_directory) if f.startswith(\"tracker_stats_\")]\n",
    "# if stats_files:\n",
    "#     latest_stats_file = sorted(stats_files)[-1]\n",
    "#     stats_df = pd.read_csv(f\"{output_directory}/{latest_stats_file}\")\n",
    "#     display(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b2e8a56-0cf0-42b6-bd73-32883f9a804b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-15 18:59:10,561 - INFO - ====== WebDriver manager ======\n",
      "2025-03-15 18:59:10,988 - INFO - Get LATEST geckodriver version for 135.0 firefox\n",
      "2025-03-15 18:59:11,592 - INFO - Driver [/Users/soodoku/.wdm/drivers/geckodriver/macos/0.36/geckodriver] found in cache\n",
      "2025-03-15 18:59:15,461 - INFO - Firefox WebDriver initialized\n",
      "2025-03-15 18:59:15,463 - INFO - Analyzing (1/2): https://example.com\n",
      "2025-03-15 18:59:15,464 - INFO - Analyzing website: https://example.com\n",
      "2025-03-15 18:59:46,168 - INFO - Analysis complete: 0 trackers, 0 tracking requests\n",
      "2025-03-15 18:59:46,171 - INFO - Saved interim results to tracker_results/interim_results_1.json\n",
      "2025-03-15 18:59:46,172 - INFO - Analyzing (2/2): https://nytimes.com\n",
      "2025-03-15 18:59:46,173 - INFO - Analyzing website: https://nytimes.com\n",
      "2025-03-15 19:00:19,684 - INFO - Analysis complete: 5 trackers, 22 tracking requests\n",
      "2025-03-15 19:00:19,693 - INFO - Saved interim results to tracker_results/interim_results_2.json\n",
      "2025-03-15 19:00:20,652 - INFO - WebDriver closed\n",
      "2025-03-15 19:00:20,676 - INFO - Results saved to tracker_results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Count</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Min</th>\n",
       "      <th>25%</th>\n",
       "      <th>Median</th>\n",
       "      <th>75%</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trackers</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tracking_requests</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.56</td>\n",
       "      <td>0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.50</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_transferred</td>\n",
       "      <td>2</td>\n",
       "      <td>23087.0</td>\n",
       "      <td>32649.95</td>\n",
       "      <td>0</td>\n",
       "      <td>11543.50</td>\n",
       "      <td>23087.0</td>\n",
       "      <td>34630.50</td>\n",
       "      <td>46174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Advertising</td>\n",
       "      <td>2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>13.44</td>\n",
       "      <td>0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>9.5</td>\n",
       "      <td>14.25</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Audio/Video Player</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Customer Interaction</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hosting Services</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Consent Management</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Site Analytics</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Utilities</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Social Media</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Adult Advertising</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Metric  Count     Mean       Std  Min       25%   Median  \\\n",
       "0               trackers      2      2.5      3.54    0      1.25      2.5   \n",
       "1      tracking_requests      2     11.0     15.56    0      5.50     11.0   \n",
       "2       data_transferred      2  23087.0  32649.95    0  11543.50  23087.0   \n",
       "3            Advertising      2      9.5     13.44    0      4.75      9.5   \n",
       "4     Audio/Video Player      2      0.0      0.00    0      0.00      0.0   \n",
       "5   Customer Interaction      2      0.0      0.00    0      0.00      0.0   \n",
       "6       Hosting Services      2      0.0      0.00    0      0.00      0.0   \n",
       "7     Consent Management      2      0.0      0.00    0      0.00      0.0   \n",
       "8         Site Analytics      2      0.0      0.00    0      0.00      0.0   \n",
       "9          Miscellaneous      2      0.0      0.00    0      0.00      0.0   \n",
       "10             Utilities      2      1.5      2.12    0      0.75      1.5   \n",
       "11          Social Media      2      0.0      0.00    0      0.00      0.0   \n",
       "12     Adult Advertising      2      0.0      0.00    0      0.00      0.0   \n",
       "\n",
       "         75%    Max  \n",
       "0       3.75      5  \n",
       "1      16.50     22  \n",
       "2   34630.50  46174  \n",
       "3      14.25     19  \n",
       "4       0.00      0  \n",
       "5       0.00      0  \n",
       "6       0.00      0  \n",
       "7       0.00      0  \n",
       "8       0.00      0  \n",
       "9       0.00      0  \n",
       "10      2.25      3  \n",
       "11      0.00      0  \n",
       "12      0.00      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Run the analysis (uncomment to execute)\n",
    "results = manager.analyze_urls(urls_to_analyze)\n",
    "\n",
    "# Display the results (if you've run the analysis)\n",
    "import pandas as pd\n",
    "# Display the results\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# First, let's find the stats files specifically\n",
    "stats_files = [f for f in os.listdir(output_directory) if f.startswith(\"tracker_stats_\")]\n",
    "\n",
    "if stats_files:\n",
    "    # Sort to get the latest one\n",
    "    latest_stats_file = sorted(stats_files)[-1]\n",
    "    \n",
    "    try:\n",
    "        # Try to read the CSV with explicit encoding\n",
    "        stats_df = pd.read_csv(f\"{output_directory}/{latest_stats_file}\", encoding='utf-8')\n",
    "        display(stats_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV: {e}\")\n",
    "        \n",
    "        # Let's inspect the file contents\n",
    "        with open(f\"{output_directory}/{latest_stats_file}\", 'r') as f:\n",
    "            print(\"First 10 lines of the file:\")\n",
    "            for i, line in enumerate(f):\n",
    "                if i < 10:\n",
    "                    print(f\"Line {i+1}: {repr(line)}\")\n",
    "                else:\n",
    "                    break\n",
    "else:\n",
    "    # If no stats files, look at what files are actually there\n",
    "    print(\"Files in output directory:\")\n",
    "    for f in os.listdir(output_directory):\n",
    "        print(f)\n",
    "    \n",
    "    # Let's look at the JSON results instead\n",
    "    json_files = [f for f in os.listdir(output_directory) if f.endswith(\".json\")]\n",
    "    \n",
    "    if json_files:\n",
    "        latest_json = sorted(json_files)[-1]\n",
    "        with open(f\"{output_directory}/{latest_json}\", 'r') as f:\n",
    "            import json\n",
    "            data = json.load(f)\n",
    "            print(f\"\\nFound {len(data)} website results in {latest_json}\")\n",
    "            \n",
    "            # Create a simple summary DataFrame\n",
    "            summary = []\n",
    "            for site in data:\n",
    "                summary.append({\n",
    "                    'url': site['url'],\n",
    "                    'trackers': site.get('trackers', 0),\n",
    "                    'tracking_requests': site.get('tracking_requests', 0),\n",
    "                    'data_transferred': site.get('data_transferred', 0)\n",
    "                })\n",
    "            \n",
    "            if summary:\n",
    "                summary_df = pd.DataFrame(summary)\n",
    "                display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3668f940-2cec-4d3a-9860-34e9c5598fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
